\documentclass{article}

\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{bm}
\DeclareRobustCommand{\rchi}{{\mathpalette\irchi\relax}}
\newcommand{\irchi}[2]{\raisebox{\depth}{$#1\chi$}}

\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=blue, citecolor=blue,
  urlcolor=blue}

\usepackage[bottom]{footmisc}
\usepackage{geometry}
\geometry{lmargin=3cm, rmargin=3cm, tmargin=3cm, bmargin=3cm}

% Algorithm
\usepackage[english, vlined, ruled]{algorithm2e}
\SetAlCapSty{}
% \SetAlCapFnt{\footnotesize}
% \SetAlCapNameFnt{\footnotesize}

\usepackage{natbib}
% \bibliographystyle{humannat}
\bibliographystyle{agsm}

\usepackage{lipsum}
\usepackage{float}
\usepackage{mathpazo}

\usepackage{booktabs}
\usepackage{tabularx}
\newcolumntype{C}{>{\centering\arraybackslash}X}

\makeatletter
\def\and{%
  \end{tabular}%
  \hskip 0em \@plus.17fil \protect$\bullet$
  \begin{tabular}[t]{c}}%
\makeatother

%-----------------------------------------------------------------------
\title{Reparametrization of COM-Poisson Regression Models with
  Applications in the Analysis of Experimental Data}

\author{
  Eduardo E. R. Junior\thanks{Corresponding author:
    \href{mailto:jreduardo@usp.br}{\nolinkurl{jreduardo@usp.br}}}
    \hspace*{.8mm}\thanks{Department of Exact Sciences, ESALQ-USP,
    Piracicaba, São Paulo, Brazil} \and
  Walmes M. Zeviani\thanks{Department of Statistics, UFPR, Curitiba,
    Paraná, Brazil} \and
  Wagner H. Bonat\footnotemark[3] \and
  Clarice G. B. Demétrio\footnotemark[2]
}

\date{\today}

<<setup, include=FALSE>>=

library(knitr)
library(xtable)
options(digits = 3, OutDec = ".",
        xtable.caption.placement = "top",
        xtable.booktabs = TRUE,
        xtable.sanitize.text.function = identity)
opts_chunk$set(
    warning = FALSE,
    message = FALSE,
    echo = FALSE,
    results = "hide",
    fig.width = 7,
    fig.height = 5,
    out.width = "1\\textwidth",
    fig.align = "center",
    fig.pos = "H",
    # dev = "tikz"
    dev.args = list(family = "Palatino")
    )

source("./codes/lattice-panels.R")
source("./codes/functions.R")

# Colors for legends
cols <- trellis.par.get("superpose.line")$col

# Useful packages
library(bbmle)
library(multcomp)
library(plyr)
library(tidyr)
library(dplyr)

@

%-----------------------------------------------------------------------

\begin{document}
\maketitle

\begin{abstract}
\lipsum[1]
\vspace{0.1cm}
\noindent\textbf{keywords:} COM-Poisson, Over/Under-dispersion, Count data
\end{abstract}

\pagebreak

\section{Introduction}
\label{introduction}

\section{Background}
\label{background}

The COM-Poisson distribution generalizes the Poisson distribution in
terms of the ratio between the probabilities of two consecutive values,
with addition of a precision parameter \cite{Sellers2010}. Let $Y$ a
COM-Poisson random variable, then
$$\frac{\Pr(Y=y-1)}{\Pr(Y=y)} = \frac{y^\nu}{\lambda}$$ while for the
Poisson distribution this ratio is $\frac{y}{\lambda}$. This allows the
distribution for overdispersion or underdispersion. The probability mass
function for the COM-Poisson random variables takes the form
\begin{equation}
  \label{eqn:pmf-cmp}
  \Pr(Y=y \mid \lambda, \nu) = \frac{\lambda^y}{(y!)^\nu Z(\lambda, \nu)},
  \qquad y = 0, 1, 2, \ldots
\end{equation},
where $\lambda > 0$, $\nu \geq 0$ and $Z(\lambda, \nu) =
\sum_{j=0}^\infty \frac{\lambda^j}{(j!)^\nu}$ is a normalizing
constant.

The $Z(\lambda, \nu)$ series diverges theorically only when $\nu=0$ and
$\lambda \geq 1$, but numerically for small values of $\nu$ combined
with large of $\lambda$, the sum is so huge it causes
\textit{overflow}. \autoref{tab:convergenceZ} shows the calculated
normalizing constants using a thousand increments, that is,
$\sum_{j=0}^{1000}\lambda^j/(j!)^\nu$ for differents of $\lambda$ and
$\phi$ $\lambda$ e $\nu$ \footnote{For $\lambda=1$ e $\nu=0$ we show Inf,
  although the numerically value is $1000$, since the series clearly
  diverges.}.

<<convergenceZ, echo=FALSE, results="asis">>=

#-----------------------------------------------------------------------
# Convergence of Z(lambda, nu) constant
computeZ <- function(lambda, nu, maxit = 1e4, tol = 1e-5) {
    z <- vector("numeric", maxit)
    j = 1
    z[j] <- exp(j * log(lambda) - nu * lfactorial(j))
    while (abs(z[j] - 0) > tol && j <= maxit) {
        j = j + 1
        z[j] <- exp(j * log(lambda) - nu * lfactorial(j))
    }
    if (lambda == 1 & nu == 0) z <- Inf
    return(sum(z, na.rm = TRUE) + 1)
}

grid <- expand.grid(
    lambda = c(0.5, 1, 5, 10, 30, 50),
    nu = seq(0, 1, length.out = 11))
grid$z <- apply(grid, 1, function(par) {
    computeZ(lambda = par[1], nu = par[2], maxit = 1e4)
})

xt <- xtabs(z ~ nu + lambda, data = grid)
caption <- paste(
    "Values for $Z(\\lambda, \\nu)$ constant (calculated numerically)",
    "for values of $\\lambda$ (0.5 to 50) and $\\phi$ (0 to 1)")

# Remove excessive scientific notation
xt2 <- gsub("e\\+00", "    ", format(xt))
xt2 <- gsub("\\|([0-9].{2}) \\|", "\\|**\\1** \\|", xt2)
print(xtable(xt2, digits = -2,
             caption = caption,
             align = "C|CCCCCC",
             # align = "ccccccc",
             label = "tab:convergenceZ"),
      include.colnames = FALSE,
      tabular.environment = "tabularx",
      width = "\\textwidth",
      add.to.row = list(
          pos = list(0, 0),
          command = c(
              " \\multicolumn{7}{c}{$\\bm{\\lambda}$} \\\\\n",
              "$\\bm{\\nu}$ & 0,5 & 1 & 5 & 10 & 30 & 50 \\\\\n")
      ))

@

An undesirable feature of COM-Poisson distribution is that the moments
cannot be solved in closed form. \citet{Shmueli2005} and
\citet{Sellers2010} using an asymptotic approximation for
$Z(\lambda,\nu)$, shows that an approximate forms can be closed by
\begin{equation}
  \label{eqn:mean-aprox}
  E(Y) \approx \lambda^{1/\nu} - \frac{\nu - 1}{2\nu} \qquad
  \textrm{and} \qquad
  \textrm{var}(Y) \approx \frac{\lambda^{1/\nu}}{\nu}\,,
\end{equation} which is particularly accurate for  $\nu \leq 1$ or
$\lambda > 10$. The authors also shows that the mean-variance
relationship can be appproximate by $\frac{1}{\nu}E(Y)$. In
\autoref{reparametrization} we assess the approximations.

A regression formulation for COM-Poisson models was proposed by
\citet{Sellers2010}, using the original parametrization. In this case,
the COM-Poisson regression is $\eta(E(Y_i)) = \log(\lambda_i)$ and the
relationship between $E(Y_i)$ and $\bm{x}_i$ is modeled
inderectly. \citet{Huang2017} shows how the means of COM-Poisson
distributions can be modelled directly. in the \autoref{eqn:pmf-cmp},
\Citeauthor{Huang2017} proposes that the parameter $\lambda$ is a
function of $\mu$ and $\nu$, given by the solution to
\begin{equation*}
  \sum_{j=0}^{\infty} (j - \mu) \frac{\lambda^j}{(y!)^\nu} = 0\,.
\end{equation*}
Thus the mean-parametrized COM-Poisson regression is $\eta(E(Y_i)) =
\log(\mu_i)$. In this article, we presented a alternative
mean-parametrization of COM-Poisson models to avoid the limitations of
original parametrization and complexity of \Citeauthor{Huang2017}
parametrization.

\section{Reparametrization}
\label{reparametrization}

<<data-approx, include=FALSE, cache=TRUE>>=

#-----------------------------------------------------------------------
# Study the approximation

#-------------------------------------------
# Mean and variance relationship
aux <- expand.grid(
    mu = seq(2, 30, length.out = 50),
    phi = seq(log(0.3), log(2.5), length.out = 50))

moments <- mapply(FUN = calc_moments,
                  mu = aux$mu,
                  phi = aux$phi,
                  MoreArgs = list(sumto = 300),
                  SIMPLIFY = FALSE)
grid <- cbind(aux, t(do.call(cbind, moments)))
grid <- transform(grid, va = mu / exp(phi))

#-------------------------------------------
# COM-Poisson probabilities
parg <- expand.grid(mu = c(5, 15), phi = log(c(0.5, 1, 2.5)))
y <- 0:30
py <- mapply(FUN = dcmp,
             mu = parg$mu,
             phi = parg$phi,
             MoreArgs = list(y = y, sumto = 100),
             SIMPLIFY = FALSE)
parg <- cbind(parg[rep(1:nrow(parg), each = length(y)), ],
              y = y, py = unlist(py))

@

\section{Estimation and Inference}
\label{estimation-and-inference}

\section{Simulation study}
\label{simulation-study}

In this section we conducted a simulation study to assess the properties
of the proposed model and estimators0. We considered average counts varying
from 3 to 27 according to a regression model structure with a continous
variable and a categorical variable with three levels. With respect to
the precision parameter $\phi$, we fixed it to four values $-1.6$,
$-1.0$, $0.0$ and $1.8$, in order to have strong overdispersed, moderate
overdispersed, equidispersed and underdispersed counts respectively. For
each value of precision parameter, we considered four different sample
sizes, 50, 100, 300 and 1000, generating 1000 datasets in each case. The
\autoref{alg:simulation} shows the details of the steps in simulation
study. In \autoref{fig:bias-plot} we show the bias of the estimators for
each scenario (combination between values of the dispersion parameter
and samples sizes) together with a confidence interval calculated as
average bias plus and minus $\Phi(0.975)$ times the standard error. The
scales are standardized for each parameter by dividing the bias by the
standard error obtained for the sample of size 50.

\begin{algorithm}
\caption{Steps in simulation study.}
\label{alg:simulation}
  \Begin{
  $\bm{\beta} = \begin{bmatrix} \beta_0 & \beta_1 & \beta_{21} &
    \beta_{22} \end{bmatrix}^\top = \begin{bmatrix} 2.0 &
    0.5 & 0.8 & -0.8 \end{bmatrix}^\top$\;
  \For{$n \in \{50, 100, 300, 1000\}$}{
    set $\bm{x}_1$ as a sequence, with $n$ elements, between $0$ and
    $1$\;
    set $\bm{x}_2$ as a repetition, with $n$ elements, of three
    categories\;
    compute $\bm{\mu}$ using $\bm{\mu} = \exp(\beta_0 + \beta_1 \bm{x}_1
    +  \beta_{21} \bm{x}_{21} + \beta_{22} \bm{x}_{22})$, where
    $\bm{x}_{21}$ and $\bm{x}_{22}$ are \textit{dummy} variable for
    $\bm{x}_2$\;
    \For{$\phi \in \{-1.6, -1.0, 0.0, 1.8\}$}{
      \Repeat{$1000$ times}{
        simule $\bm{y}$ from COM-Poisson distribution with $\bm{\mu}$
        and $\phi$ parameters\;
        fit COM-Poisson$_\mu$ regression model to $\bm{y}$ data with
        $\bm{X} = \begin{bmatrix} \bm{1} & \bm{x}_1 & \bm{x}_{21} &
          \bm{x}_{22} \end{bmatrix}$ design matrix\;
        get $\hat{\bm{\theta}} = \begin{bmatrix} \hat{\phi} & \hat{\beta}_0 &
          \hat{\beta}_1 & \hat{\beta}_{21} & \hat{\beta}_{22}
        \end{bmatrix}^\top$\;
        get confidence intervals for $\hat{\bm{\theta}}$ by quadratic
        approximation at the maximum likelihood estimate
        (assumes $\hat{\bm{\theta}} \sim \mathcal{N}(\hat{\bm{\theta}},
        \sqrt{-\bm{v}})$, where $\bm{v}$ is a diagonal of the inverse of
        the hessian matrix)\;
      }
    }
  }
}
\end{algorithm}

<<load-simulation, cache=TRUE>>=

# Configuration
B <- 1000
beta <- c("b0" = 2, "b1" = 0.5, "b21" = 0.8, "b22" = -0.8)
phis <- c(0, -1.6, -1, 1.8)
names(phis) <- sprintf("phi=%s", phis)

sizes <- c(50, 100, 300, 1000)
names(sizes) <- sprintf("n=%s", sizes)

# Load results
results <- readRDS("./codes/simulation.rds")

@

<<bias-data, cache=TRUE>>=

#-----------------------------------------------------------------------
# Compute standardized bias
std <- lapply(results["n=50"], function(x) {
    ind <- names(x); names(ind) <- ind
    lapply(ind, function(y) {
        bhat <- t(vapply(x[[y]], "[[", double(5), "coef"))
        real <- matrix(c(phis[y], beta), byrow = TRUE,
                       nrow = B, ncol = 5)
        matrix(apply(bhat - real, 2, sd, na.rm = TRUE),
               byrow = TRUE, nrow = B, ncol = 5)
    })
})

aux <- ldply(lapply(results, function(x) {
    ind <- names(x); names(ind) <- ind
    out <- lapply(ind, function(y) {
        bhat <- t(vapply(x[[y]], "[[", double(5), "coef"))
        real <- matrix(c(phis[y], beta), byrow = TRUE,
                       nrow = B, ncol = 5)
        # (bhat - real)                 # raw bias
        (bhat - real) / std[[1]][[y]] # standardized bias
    })
    ldply(out, .id = "phi")
}), .id = "n")

# Organize the results
aux <- na.omit(aux)
bias <- gather(aux, param, bias, phi2:b22, factor_key = TRUE)
bias$phi <- ordered(bias$phi, c("phi=-1.6", "phi=-1", "phi=0",
                                "phi=1.8"))

@

The results in \autoref{fig:bias-plot} show that for all dispersed
levels, both the expected bias and standard error tend to 0 as the
sample size is increased. The estimators for the regression parameters
are unbiased, consistency and their empirical distributions are
symmetric. For the precision parameter, the estimator is asymptotically
unbiased, in small samples the parameter is overestimated and the
empirical distribution is right-skewed. \autoref{fig:coverage-plot}
presents the confidence interval coverage rate based on quadratic
approximation at the maximum likelihood estimate by sample size and
dispersed levels.

<<bias-plot, cache=TRUE, fig.height=5, fig.width=8, fig.cap="Distributions of standardized bias (gray points) and average with confidence intervals (black segments) by differents sample sizes and dispersion levels.">>=

# Distributions of bias and average with confidence intervals
ci <- function(x) {
    ci <- mean(x) + c(-1, 0, 1) * qnorm(0.975) * sd(x)
    names(ci) <- c("lwr", "fit", "upr")
    ci
}
cidata <- aggregate(bias ~ n + phi + param, data = bias, ci)

key <- list(
    type = "o",
    divide = 1,
    columns = 4,
    title = "Sample size",
    cex.title = 1.1,
    lines = list(pch = c(21:24), cex = 0.8),
            text = list(names(sizes))
)

fl <- parse(text = gsub("=", "==", levels(bias$phi)))
yl <- parse(text = c("hat(phi)",
                     paste0("hat(beta)[", c(0, 1, 21, 22), "]")))

xyplot(param ~ bias | phi, groups = n, data = bias,
       panel = panel.superpose,
       layout = c(4, 1),
       key = key,
       strip = strip.custom(factor.levels = fl),
       scales = list(y = list(labels = yl)),
       ylab = "",
       xlab = "Standardized Bias",
       jitter.y = TRUE,
       factor = 0.1,
       gap = 0.3,
       alpha = 0.6,
       col = "gray80",
       cex = 0.7,
       panel.groups = function(x, y, group.number,
                               subscripts, gap, ...){
           noise <- centfac(factor(levels(bias$n)), space = gap)
           noise <- sort(noise)
           panel.xyplot(x, y + noise[group.number], ...)
       }) +
    as.layer(
        segplot(param ~ bias[, "lwr"] + bias[, "upr"] | phi,
                centers = bias[, "fit"],
                data = cidata,
                draw = FALSE,
                horizontal = TRUE,
                layout = c(4, 1),
                groups = n, gap = 0.3,
                key = key,
                pch = 21:24,
                cex = 0.7,
                lwd = 2,
                panel = function(...) {
                    panel.groups.segplot(...)
                    panel.abline(v = 0, lty = 2)
                    panel.abline(h = 1:5, col = "lightgray", lty = 2)
                })
    )
@

<<coverage-data>>=

#-----------------------------------------------------------------------
# Compute coverage rate
aux <- ldply(lapply(results, function(x) {
    ind <- names(x); names(ind) <- ind
    out <- lapply(ind, function(y) {
        ind <- lapply(x[[y]], function(z) {
            real <- c(phis[[y]], beta)
            cint <- z[["cint"]]
            ind <- as.integer(cint[, 1] < real & cint[, 2] > real)
            names(ind) <- c("phi2", names(beta))
            ind
        })
        do.call("rbind", ind)
    })
    ldply(out, .id = "phi")
}), .id = "n")

# Organize the results
aux <- na.omit(aux)
coverage <- gather(aux, param, coverage, phi2:b22, factor_key = TRUE)
coverage$phi <- ordered(coverage$phi, c("phi=-1.6", "phi=-1", "phi=0",
                                        "phi=1.8"))
coverage$n <- as.numeric(gsub("n=([0-9]+)", "\\1", coverage$n))
covdata <- aggregate(coverage ~ n + phi + param, data = coverage,
                     function(x) sum(x == 1) / length(x))

@

The coverage rates in \autoref{fig:coverage-plot} show that for the
regression parameters the empirical coverage rates are close to the
nominal level of 95\% for sample sizes greater than 100 and all
dispersed levels. For the precision parameter the empirical coverage
rates are slightly lower than the nominal level, however, they become
closer for large samples. The worst scenario is when we have small
sample size and strong overdispersed counts.

<<coverage-plot, fig.height=4, fig.width=9, fig.cap="Coverage rate based on confidence intervals obtained by quadratic approximation for differents sample sizes and dispersion levels.">>=

fl <- parse(text = gsub("=", "==", levels(bias$phi)))
yl <- parse(text = c("hat(phi)",
                     paste0("hat(beta)[", c(0, 1, 21, 22), "]")))
xyplot(coverage ~ n | param,
       type = c("g", "p", "l"),
       groups = phi,
       data = covdata,
       pch = 19,
       lwd = 1.5,
       layout = c(NA, 1),
       xlab = "Sample size",
       ylab = "Coverage rate",
       par.settings = list(
           superpose.symbol = list(pch = 19),
           layout.heights = list(strip = 1.5)
       ),
       auto.key = list(
           column = 4,
           lines = TRUE,
           text = fl
       ),
       strip = strip.custom(
           factor.levels = yl
       ),
       panel = function(x, y, ...) {
           panel.xyplot(x, y, ...)
           panel.abline(h = 0.95, lty = 2)
       })

@

\section{Case studies}
\label{case-studies}

In this section, we report three illustrative examples of real count
data analysis obtained of the experimental research. We considered as
alternative models for the analysis the standard Poisson model, the
COM-Poisson model in two forms (original and mean parametrization) and
Quasi-Poisson model, based on second-moment assumptions. The data sets
and \texttt{R} codes for their analysis are available on online
supplements.

\subsection{Artificial defoliation in cotton phenology}
\label{case-cotton}

This example relates to cotton plants (\textit{Gossypium hirsutum})
submetted to five levels of artificial defoliation (\texttt{des}) and
observed on five growth stages (\texttt{est}). The purpose of this
research was to study the effect of defoliation levels at different
growth stages of cotton plants on the observed number of bolls
produced. The study was conducted in a greenhouse and the experimental
design was completely randomized with five replicates. This data set was
analysed in \citet{Zeviani2014} using the \textit{Gamma-Count}
distribution.

Following the results of \citet{Zeviani2014}, we considered the linear
predictor specified by
$$\log(\mu_{ij}) = \beta_0 + \beta_{1j} \textrm{def}_i + \beta_{2j}
\textrm{def}_i^2$$
where $\mu_{ij}$ is the expected number of cotton bolls for the $i$-th
defoliation level ($i=$ 1: 0\%, 2: 25\%, 3: 50\%, 4: 75\% e 5: 100\%)
and $j$-th growth stage ($j$ = 1: vegetative, 2: flower bud, 3: blossom,
4: boll, 5: boll open), that is, we have a second order effect of
defoliation in each growth stage. The parameters estimates and
goodness-of-fit measures for the Poisson, COM-Poisson, COM-Poisson$_\mu$
e quasi-Poisson models are presented in \autoref{tab:coef-cotton}.

<<fit-cotton, cache=TRUE, include=FALSE>>=

#-----------------------------------------------------------------------
# Load data
# data(cottonBolls, package = "cmpreg")
cottonBolls <- read.table("./data/cottonBolls.txt",
                          header = TRUE, sep = "\t")
cottonBolls$est <- ordered(
    cottonBolls$est,
    c("vegetative", "flower bud", "blossom", "boll", "boll open")
)

#-----------------------------------------------------------------------
# Fit models
mnames <- c("PO", "C1", "C2", "QP")

# Predictor, following Zeviani et al. (2014)
form1 <- ncap ~ est:(des + I(des^2))

m1PO <- glm(form1, data = cottonBolls, family = poisson)
time11 <- system.time(
    m1C1 <- fitcm(form1, data = cottonBolls, model = "CP", sumto = 50)
)
time12 <- system.time(
    m1C2 <- fitcm(form1, data = cottonBolls, model = "CP2", sumto = 50)
)
m1QP <- glm(form1, data = cottonBolls, family = quasipoisson)

models.ncap <- list(m1PO, m1C1, m1C2, m1QP)
names(models.ncap) <- mnames

# Numbers of calls to loglik and numerical gradient
c11 <- models.ncap$C1@details$counts
c12 <- models.ncap$C2@details$counts

# LRT between Poisson and COM-Poisson (test: phi == 0)
lrt.ncap <- getAnova(m1PO, m1C2)

@

\begin{table}[h]
\centering
\caption{Parameter estimates (Est) and ratio between estimate and
  standard error (SE) for the four model strategies for the cotton
  experiment.}
\label{tab:coef-cotton}
\begin{tabularx}{\textwidth}{lCCCCCCCC}
  \toprule
  & \multicolumn{2}{c}{Poisson} &
    \multicolumn{2}{c}{COM-Poisson} &
    \multicolumn{2}{c}{COM-Poisson$_\mu$} &
    \multicolumn{2}{c}{Quasi-Poisson} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9}
<<results-cotton, results="asis">>=

#-----------------------------------------------------------------------
# Goodness of fit measures and estimate parameters

# GoF measures
measures.ncap <- lapply(models.ncap, function(x)
    c("LogLik" = logLik(x), "AIC" = AIC(x), "BIC" = BIC(x)))

# Get the estimates
co1 <- coef(m1C2)
est <- lapply(models.ncap, FUN = function(x) getCoefs(x))
est.ncap <- do.call(cbind, est)

# Organize in table
pnames <- c("\\phi\\,,\\,\\sigma", "\\beta_0",
            paste0("\\beta_{1", 1:5, "}"),
            paste0("\\beta_{2", 1:5, "}"))
rownames(est.ncap) <- paste0("$", pnames, "$")
meds <- apply(do.call(cbind, measures.ncap), 1, function(x) {
    x <- formatC(x, getOption("digits"), format = "f")
    x <- gsub("NA", "---", x)
    paste(paste0("\\multicolumn{2}{c}{", x, "}"),
          collapse = " & ")
})
text_gof <- paste(paste(names(meds), "&", meds),
                  collapse = "\\\\\n ")

append_gof <- list(
    pos = list(nrow(est.ncap)),
    command = paste("\\specialrule{0.01em}{0.3em}{0.3em} \n",
                    text_gof, "\\\\\n",
                    "\\bottomrule"))
print.xtable(xtable(est.ncap, digits = 4,
                    label = "tab:coef-cotton"),
             hline.after = 0,
             only.contents = TRUE,
             add.to.row = append_gof)

@
\end{tabularx}
\end{table}

The results presented in \autoref{tab:coef-cotton} show that the
goodness-of-fit measures (maximum log-likelihood, AIC and BIC) are quite
similar between COM-Poisson and COM-Poisson$_\mu$. This shows that the
reparametrization doesn't change the model fit, as expected. The Poisson
model is clearly unsuitable, being overly conservative. The difference
between the log-likelihoods of the Poisson and COM-Poisson$_\mu$ models
is \Sexpr{lrt.ncap[2, 4]}. Comparing this value with the chi-square
distribution, with one degree of freedom, we have these models are
significantly differents ($\phi \neq 0$). The estimated value of
precision parameter, $\hat{\phi}$ is \Sexpr{co1[1]}, indicating
underdispersion.

\autoref{tab:coef-cotton} also shows the advantage of COM-Poisson$_\mu$
(reparametrized), since the estimates are quite similiar to obtained by
the Poisson model, whereas estimates obtained by the COM-Poisson model
in original parametrization are on a non-interpretable scale. The ratios
between estimates and their respective standard deviations for the
COM-Poisson models are very close to ratios obtained by quasi-Poisson
model. However, it is importante to note that COM-Poisson model is a
full parametric approach, that is, there is a probability distribution
associate to counts.

In the \autoref{fig:pred-cotton} are presented the observed values and
curves of fitted values with confidence intervals (95\%) as functions of
the defoliation level for each growth stage. The fitted values are same
for both models, but confidence intervals are bigger for Poisson model
because the equidispersion assumption. The results from COM-Poisson
models are consistent with those from the Gamma-Count model, fitted by
\cite{Zeviani2014}, Poisson-Tweedie model, fitted by \cite{Bonat2017}
and alternative COM-Poisson parametrization, fitted by \cite{Huang2017},
in that both methods indicate underdispersion and significant effects of
defoliation for the vegetative, blossom and boll growth stages.

<<pred-cotton, fig.height=3.5, fig.width=8.5, fig.cap="Scatterplots of the observed data and curves of fitted values with 95\\% confidence intervals as functions of the defoliation level for each growth stage.">>=

#-----------------------------------------------------------------------
# Prediction

# Data for prediction
pred <- with(cottonBolls,
             expand.grid(
                 est = levels(est),
                 des = seq(min(des), max(des), l = 20)
             ))
qn <- qnorm(0.975) * c(fit = 0, lwr = -1, upr = 1)

# Design matrix for prediction
X <- model.matrix(update(form1, NULL~.), pred)

# Considering Poisson
aux <- exp(confint(
    glht(m1PO, linfct = X), calpha = univariate_calpha())$confint)
colnames(aux) <- c("fit", "lwr", "upr")
aux <- data.frame(modelo = "Poisson", aux)
predPO.ncap <- cbind(pred, aux)

# Considering COM-Poisson
aux <- predictcm(m1C1, newdata = X)
aux <- data.frame(modelo = "COM-Poisson", aux)
predC1.ncap <- cbind(pred, aux)

# Considering COM-Poisson (mean parametrization)
aux <- predictcm(m1C2, newdata = X)
aux <- data.frame(modelo = "COM-Poisson2", aux)
predC2.ncap <- cbind(pred, aux)

# Considering Quasi-Poisson
aux <- exp(confint(
    glht(m1QP, linfct = X), calpha = univariate_calpha())$confint)
colnames(aux) <- c("fit", "lwr", "upr")
aux <- data.frame(modelo = "Quasi-Poisson", aux)
predQP.ncap <- cbind(pred, aux)

# Representing the confidence intervals
pred.ncap <- rbind(predPO.ncap, predC1.ncap, predC2.ncap, predQP.ncap)

# Legend
key <- list(columns = 4,
            cex = 0.9,
            lines = list(col = 1, lty = rev(1:4)),
            text = list(parse(
                text = c("'Poisson'", "'COM-Poisson'",
                         "'COM-Poisson'[mu]", "'Quasi-Poisson'"))
                ))

# Graph
xyplot(ncap ~ des | est,
       data = cottonBolls,
       layout = c(NA, 1),
       as.table = TRUE,
       grid = TRUE,
       type = "p",
       xlab = "Artificial defoliation level",
       ylab = "Number of bolls produced",
       spread = 0.05,
       key = key,
       alpha = 0.6,
       panel = panel.beeswarm) +
    as.layer(
        xyplot(fit ~ des | est,
               auto.key = TRUE,
               data = pred.ncap,
               groups = modelo,
               type = "l",
               layout = c(NA, 1),
               as.table = TRUE,
               col = 1,
               ly = pred.ncap$lwr,
               uy = pred.ncap$ upr,
               cty = "bands",
               fill = "gray80",
               alpha = 0.1,
               panel = panel.superpose,
               panel.groups = panel.cbH,
               prepanel = prepanel.cbH,
               lty = rev(1:4))
    )

@

In order to assess the orthogonality between $\bm{\mu}$ and $\phi$ in
the COM-Poisson$_\mu$ parametrization, \autoref{tab:corr-cotton}
presents the empirical correlations between precision and regression
parameters, obtained by variance and covariance matrix. The correlations
are pratically null considering the COM-Poisson$_\mu$, whereas to the
original parametrization they are quite high. This reflects a better
performance of the maximization algorithm in mean-parametrization model,
in this case COM-Poisso$_\mu$ fit was \Sexpr{time12[3] * 100 /
  time11[3]}\% slower then COM-Poisson model.

<<corr-cotton, results="asis">>=

#-----------------------------------------------------------------------
# Correlation between estimates
corr.ncap <- do.call("rbind",
                     lapply(models.ncap[c("C1", "C2")],
                            function(x) cov2cor(vcov(x))[1, -1]))

# Organize on table
rownames(corr.ncap) <- paste0("COM-Poisson", c("", "$_\\mu$"))
colnames(corr.ncap) <- gsub("beta", "hat{\\\\beta}", pnames[-1])

caption <- paste("Empirical correlations between $\\hat{\\phi}$ and",
                 "$\\hat{\\bm{\\beta}}$ for the two parametrizations",
                 "of COM-Poisson model fit to underdispersed data.")
print(xtable(corr.ncap,
             align = c("lccccccccccc"),
             caption = caption,
             digits = 3,
             label = "tab:corr-cotton"),
      size = "small",
      sanitize.rownames.function = identity,
      sanitize.colnames.function = function(x) sprintf("$%s$", x))

@

\subsection{Soil moisture and potassium doses on soybean culture}
\label{case-soybean}

The second example is a experiment completely randomized block with
treatments in a $5\times 3$ factorial arrangement about soybean
culture. The aim of this study was to evaluate the effects of potassium
doses (\texttt{K}) applied to soil (0, 0.3, 0.6, 1.2 e 1.8 100mg
dm$^{-3}$) and soil humidity (\texttt{umid}) levels (37.5, 50, 62.5\%,
which represent few, ideal and abundance water repectively) on the
soybean production. The experiment was carried out in a greenhouse, in
pots with two plants, and the count variable measured was the number of
grains per pot \citep{Serafim2012}. \autoref{fig:desc-soy} (left) shows
the number of grains recorded for each combination of potassium dose and
humidity level, it is importante to note the indication of a quadratic
level of the potassium levels. Most points in the sample means and
variances dispersion diagram (right) are above the identity line,
suggesting overdispersion.

<<fit-soy, cache=TRUE, include=FALSE>>=

#-----------------------------------------------------------------------
# Load data
# data(soyaBeans, package = "cmpreg")
soyBeans <- read.table("./data/soyaBeans.txt",
                        header = TRUE, sep = "\t")
soyBeans$umid <- as.factor(soyBeans$umid)
soyBeans <- soyBeans[-74, ] # Incorrect observation
soyBeans <- transform(soyBeans, K = K / 100)

#-----------------------------------------------------------------------
# Fit models

# Predictor
form2 <-  ngra ~ bloc + umid * K + I(K^2)

m2PO <- glm(form2, data = soyBeans, family = poisson)
time21 <- system.time(
    m2C1 <- fitcm(form2, data = soyBeans, model = "CP", sumto = 700)
)
time22 <- system.time(
    m2C2 <- fitcm(form2, data = soyBeans, model = "CP2", sumto = 700)
)
m2QP <- glm(form2, data = soyBeans, family = quasipoisson)

models.ngra <- list(m2PO, m2C1, m2C2, m2QP)
names(models.ngra) <- mnames

# Numbers of calls to loglik and numerical gradient
c21 <- models.ngra$C1@details$counts
c22 <- models.ngra$C2@details$counts

# # Profile extra parameter
# profs.ngra <- lapply(list(c(m2C1, "phi"), c(m2C2, "phi2")),
#                      function(x) myprofile(x[[1]], x[[2]]))
# profs.ngra <- do.call("rbind", profs.ngra)

# LRT between Poisson and COM-Poisson (test: phi == 0)
lrt.ngra <- getAnova(m2PO, m2C2)

@

<<desc-soy, fig.pos="H", fig.height=4, fig.width=8, fig.cap="Number of grains per pot for each potassium dose and humidity level (left) and sample mean agains sample variance of the five replicates for each experimental treatment (right).">>=

#-----------------------------------------------------------------------
# Exploratory analysis

# Scatter plot
xy1 <- xyplot(ngra ~ K | umid,
              data = soyBeans,
              xlab = "Potassium fertilization level",
              ylab = "Number of grains per pot",
              type = c("p", "g", "smooth"),
              as.table =  TRUE,
              layout = c(2, 2),
              strip = strip.custom(
                  strip.names = TRUE, var.name = "humidity",
                  factor.levels = paste0(levels(soyBeans$umid), "%")))

# Sample variance vs sample mean (evidence in favor of the
# overdispersion).
mv <- soyBeans %>%
    group_by(K, umid) %>%
    summarise(mu = mean(ngra), va = var(ngra))
xlim <- ylim <- extendrange(c(mv$mu, mv$va), f = 0.05)

xy2 <- xyplot(va ~ mu,
              data = mv,
              type = c("p", "r", "g"),
              xlim = xlim,
              ylim = ylim,
              xlab = expression("Sample"~"mean"~(bar(y))),
              ylab = expression("Sample"~"variance"~(s^2)),
              panel = function(...) {
                  panel.xyplot(...)
                  panel.abline(a = 0, b = 1, lty = 2)
              })

print(xy1, split = c(1, 1, 2, 1), more = TRUE)
print(xy2, split = c(2, 1, 2, 1), more = FALSE)

@

For the analysis of this data set we proposed, based on descriptive
analysis \autoref{fig:desc-soy}, the linear predictor specified as a
linear doses for each humidity level and a global quadratic dose effect,
i.e
$$
\log(\mu_{ijk}) = \beta_0 + \gamma_i + \tau_j +
  \beta_{1}\texttt{K}_k + \beta_{2}\texttt{K}_k^2 +
  \beta_{3j}\texttt{K}_k
$$
with $i=$1: block II, 2: block III, 3: block IV e 4: block V; $j=$1:
50\% e 2: 62.5\%; and $k=$1: 0.0, 2: 0.3, 3: 0.6, 4: 1.2, 5: 1.8 100mg
dm$^{-3}$, where $\gamma_i$ is the effect of $i$-th block, $\tau_j$ is
the effect of $j$-th humidity level and $\beta_{3j}$ is the first order
potassium effect (\texttt{K}) for the $j$-th humidity level
(\texttt{umid}). \autoref{tab:coef-soy} presents the estimates, ratio
between estimate and standard deviation and goodness-of-fit measures for
the alternative models fitted.

The results in \autoref{tab:coef-soy} has similar interpretations to
results presented in \autoref{case-cotton}. The two parametrization of
COM-Poisson presented very similar goodness-of-fit measures and better
than Poisson model. The difference between the log-likelihoods of the
Poisson and COM-Poisson models is \Sexpr{lrt.ngra[2, 4]}, indicating
that $\phi$ is significatly different of zero. With respect to the
regression parameters, the similarities between models are analogous to
the previous section. Both models agree on the indication of effects,
however the Poisson model indicates the effects with greater
significance, because it doesn't fit the extra variability.

\begin{table}[ht]
\centering
\caption{Parameter estimates (Est) and ratio between estimate and
  standard error (SE) for the four model strategies for the soybean
  experiment.}
\label{tab:coef-soy}
\begin{tabularx}{\textwidth}{lCCCCCCCC}
  \toprule
  & \multicolumn{2}{c}{Poisson} &
    \multicolumn{2}{c}{COM-Poisson} &
    \multicolumn{2}{c}{COM-Poisson$_\mu$} &
    \multicolumn{2}{c}{Quasi-Poisson} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9}
<<results-soya, results="asis">>=

#-----------------------------------------------------------------------
# Goodness of fit measures and estimate parameters

# GoF measures
measures.ngra <- lapply(models.ngra, function(x)
    c("LogLik" = logLik(x), "AIC" = AIC(x), "BIC" = BIC(x)))

# Get the estimates
co2 <- coef(m2C2)
est <- lapply(models.ngra, FUN = function(x) getCoefs(x))
est.ngra <- do.call(cbind, est)

# Organize in table
pnames <- c("\\phi\\,,\\,\\sigma", "\\beta_0",
            paste0("\\gamma_{", 1:4, "}"),
            paste0("\\tau_{", 1:2, "}"),
            "\\beta_1", "\\beta_2",
            paste0("\\beta_{3", 1:2, "}"))

rownames(est.ngra) <- paste0("$", pnames, "$")
meds <- apply(do.call(cbind, measures.ngra), 1, function(x) {
    x <- formatC(x, getOption("digits"), format = "f")
    x <- gsub("NA", "---", x)
    paste(paste0("\\multicolumn{2}{c}{", x, "}"),
          collapse = " & ")
})
text_gof <- paste(paste(names(meds), "&", meds),
                  collapse = "\\\\\n ")

append_gof <- list(
    pos = list(nrow(est.ngra)),
    command = paste("\\specialrule{0.01em}{0.3em}{0.3em} \n",
                    text_gof, "\\\\\n",
                    "\\bottomrule"))
print.xtable(xtable(est.ngra, digits = 4,
                    label = "tab:coef-soy"),
             hline.after = 0,
             only.contents = TRUE,
             add.to.row = append_gof)

@
\end{tabularx}
\end{table}

The infinite sum $Z(\mu, \phi)$ in cases of oversidepersed counts needs
a greater upper bound for the convergence, making the computation of the
likelihood more expansive. In this case, the upper bound was 700. The
number of likelihood computations, on the BFGS algorithm, was
\Sexpr{c21[1]} and \Sexpr{c22[2]} for the original and
mean-parametrization and the time to fit was \Sexpr{time21[3]} and
\Sexpr{time22[3]} seconds respectively. This may be due the
well-behaviour of likelihood function for orthogonal parameters. In
\autoref{tab:corr-soy} we present the empirical correlations between
regression and precision parameter. The correlations are close to zero
for the COM-Poisson$_\mu$ parametrization, indicating the empirical
orthogonality between $\mu$ and $\phi$ on COM-Poisson$_\mu$
distribution.

<<corr-soy, results="asis">>=

##----------------------------------------------------------------------
## Correlation between estimates
corr.ngra <- do.call("rbind",
                     lapply(models.ngra[c("C1", "C2")],
                            function(x) cov2cor(vcov(x))[1, -1]))

## Organize on table
rownames(corr.ngra) <- paste0("COM-Poisson", c("", "$_\\mu$"))
colnames(corr.ngra) <- gsub("(beta|tau|gamma)", "hat{\\\\\\1}",
                            pnames[-1])

caption <- paste("Empirical correlations between $\\hat{\\phi}$ and",
                 "$\\hat{\\bm{\\beta}}$ for the two parametrizations",
                 "of COM-Poisson model fit to overdispersed data.")
print(xtable(corr.ngra,
             align = c("lccccccccccc"),
             caption = caption,
             digits = 3,
             label = "tab:corr-soy"),
      size = "small",
      sanitize.rownames.function = identity,
      sanitize.colnames.function = function(x) sprintf("$%s$", x))


@

The observed counts and fitted curvers for each humidity level with
confidence bands are show in \autoref{fig:pred-soy}. The fitted values
are identical both models, leading the same conclusions. On the other
hand, confindence bands for the Poisson model are smaller due to
equidispersion assumption. Considering COM-Poisson models and
quasi-Poisson approach, the confidence bands are quite similar, which
shows their flexibility.

<<pred-soy, fig.pos="H", fig.height=3.8, fig.width=8, fig.cap="Dispersion diagrams of grain counts as function of potassium doses and humidity levels with fitted curves and confidence intervals (95\\%).">>=

#-----------------------------------------------------------------------
# Prediction

# Data for prediction
pred <- with(soyBeans,
             expand.grid(
                 bloc = factor(levels(bloc)[1], levels = levels(bloc)),
                 umid = levels(umid),
                 K = seq(min(K), max(K), l = 20)
             ))
qn <- qnorm(0.975) * c(fit = 0, lwr = -1, upr = 1)

# Design matrix for prediction
X <- model.matrix(update(form2, NULL ~ .), pred)
bl <- attr(X, "assign") == 1
X[, bl] <- X[, bl] + 1/(sum(bl) + 1)

# Considering Poisson
aux <- exp(confint(
    glht(m2PO, linfct = X), calpha = univariate_calpha())$confint)
colnames(aux) <- c("fit", "lwr", "upr")
aux <- data.frame(modelo = "Poisson", aux)
predPO.ngra <- cbind(pred, aux)

# Considering COM-Poisson
aux <- predictcm(m2C1, newdata = X)
aux <- data.frame(modelo = "COM-Poisson", aux)
predC1.ngra <- cbind(pred, aux)

# Considering COM-Poisson (mean parametrization)
aux <- predictcm(m2C2, newdata = X)
aux <- data.frame(modelo = "COM-Poisson2", aux)
predC2.ngra <- cbind(pred, aux)

# Considering Quasi-Poisson
aux <- exp(confint(
    glht(m2QP, linfct = X), calpha = univariate_calpha())$confint)
colnames(aux) <- c("fit", "lwr", "upr")
aux <- data.frame(modelo = "Quasi-Poisson", aux)
predQP.ngra <- cbind(pred, aux)

# Representing the confidence intervals
pred.ngra <- rbind(predPO.ngra, predC1.ngra, predC2.ngra, predQP.ngra)

# Legend
key <- list(columns = 4,
            cex = 0.9,
            lines = list(col = 1, lty = rev(1:4)),
            text = list(parse(
                text = c("'Poisson'", "'COM-Poisson'",
                         "'COM-Poisson'[mu]", "'Quasi-Poisson'"))
                )
            )

# Graph
update(xy1, layout = c(NA, 1), type = c("p", "g"),
       alpha = 0.6, key = key) +
    as.layer(
        xyplot(fit ~ K | umid,
               data = pred.ngra,
               groups = modelo,
               type = "l",
               col = 1,
               ly = pred.ngra$lwr,
               uy = pred.ngra$upr,
               cty = "bands",
               fill = "gray80",
               alpha = 0.1,
               panel = panel.superpose,
               panel.groups = panel.cbH,
               prepanel = cmpreg::prepanel.cbH,
               lty = rev(1:4))
    )

@


\subsection{Assessing toxicity of pollutants in aquatic systems}

The data set come from an experiment to measure the reproductive
toxicity of a herbicide, nitrofen, on a species of zooplankton
(\textit{Ceriodaphnia dubia}). 50 animals were randomized into batches
of 10 and each batch was put in a solution with a measured concentration
of nitrofen (0, 0.8, 1.6, 2.35 e 3.10 mug$/10^2$litre)
(\texttt{dose}). Then the number of total live offspring was recorded
\cite{Bailer1994}.

<<fit-ovos, cahe=TRUE, include=FALSE>>=

#-----------------------------------------------------------------------
# Load data
# data(nitrofen, package = "boot")
# data(Paula, package = "labestData")
# nitrofen <- PaulaEx4.6.20
nitrofen <- read.table("./data/nitrofen.txt",
                       header = TRUE, sep = "\t")
nitrofen <- transform(nitrofen, dose = dose / 100)

#-----------------------------------------------------------------------
# Fit models
mnames <- c("PO", "C1", "C2", "QP")

# Predictors
form31 <-  novos ~ dose
form32 <-  novos ~ dose + I(dose^2)
form33 <-  novos ~ dose + I(dose^2) + I(dose^3)

predictors <- list("pred1" = form31, "pred2" = form32, "pred3" = form33)
fmodels.ovos <- lapply(predictors, function(form) {
    PO <- glm(form, data = nitrofen, family = poisson)
    C1 <- fitcm(form, data = nitrofen, model = "CP", sumto = 100)
    C2 <- fitcm(form, data = nitrofen, model = "CP2", sumto = 100)
    QP <- glm(form, data = nitrofen, family = quasipoisson)
    list("PO" = PO, "C1" = C1, "C2" = C2, "QP" = QP)
})

#-----------------------------------------------------------------------
# LRT for nested models

# Poisson
auxPO <- lapply(fmodels.ovos, function(x) x$PO)
do.call("getAnova", auxPO)

# COM-Poisson standard
auxC1 <- lapply(fmodels.ovos, function(x) x$C1)
do.call("getAnova", auxC1)

# COM-Poisson mean-parameterized
auxC2 <- lapply(fmodels.ovos, function(x) x$C2)
do.call("getAnova", auxC2)

# Quasi-Poisson
auxQP <- lapply(fmodels.ovos, function(x) x$QP)
do.call("getAnova", auxQP)

#--------------------------------------------
# Separe the choose models
form3 <- form33
m3PO <- fmodels.ovos$pred3$PO
m3C1 <- fmodels.ovos$pred3$C1
m3C2 <- fmodels.ovos$pred3$C2
m3QP <- fmodels.ovos$pred3$QP

models.ovos <- list(m3PO, m3C1, m3C2, m3QP)
names(models.ovos) <- mnames

# Numbers of calls to loglik and numerical gradient
models.ovos$C1@details$counts
models.ovos$C2@details$counts

@

For this data set we proposed three linear preditors. We compare the
performance of models using the likelihood ratio tests to select the
systematic part of model. The linear predictors are
\begin{center}
\begin{minipage}{12cm}
Preditor 1: $\log(\mu_i) = \beta_0 + \beta_1 \texttt{dose}_i$\\
Preditor 2: $\log(\mu_i) = \beta_0 + \beta_1 \texttt{dose}_i +
             \beta_2 \texttt{dose}_i^2$\\
Preditor 3: $\log(\mu_i) = \beta_0 + \beta_1 \texttt{dose}_i +
             \beta_2 \texttt{dose}_i^2 + \beta_3 \texttt{dose}_i^3$.
\end{minipage}
\end{center}

\begin{table}[ht]
\centering
\caption{Model fit measures and comparisons between predictors and models.}
\label{tab:anova-ovos}
\begin{tabularx}{\textwidth}{lCCCCCrC}
  \toprule
 Poisson & np & $\ell$ & AIC & 2(diff $\ell$) & diff np & P($>\rchi^2$) & \\
 \midrule
<<anova-ovos1, results="asis">>=

auxPO <- lapply(fmodels.ovos, function(x) x$PO)
tab <- do.call("getAnova", c(print = FALSE, auxPO))
tab <- cbind(tab, NA)
rownames(tab) <- paste("Preditor", rownames(tab))
digits <- c(1, 0, 3, 3, 3, 0, -2, 3)
print(xtable(tab, digits = digits),
      include.colnames = FALSE,
      hline.after = NULL,
      only.contents = TRUE)

@
\specialrule{0em}{0.5em}{0em} %% Apenas para espaçamento
  COM-Poisson & np & $\ell$ & AIC & 2(diff $\ell$) & diff np &
  P($>\rchi^2$) & $\hat{\phi}$ \\
  \midrule
<<anova-ovos2, results="asis">>=

auxC1 <- lapply(fmodels.ovos, function(x) x$C1)
tab <- do.call("getAnova", c(print = FALSE, auxC1))
tab <- cbind(tab, sapply(auxC1, function(x) coef(x)[1]))
rownames(tab) <- paste("Preditor", rownames(tab))
print(xtable(tab, digits = digits),
      include.colnames = FALSE,
      hline.after = NULL,
      only.contents = TRUE)

@
\specialrule{0em}{0.5em}{0em} %% Apenas para espaçamento
  COM-Poisson$_\mu$ & np & $\ell$ & AIC & 2(diff $\ell$) & diff np &
  P($>\rchi^2$) & $\hat{\phi}$ \\
  \midrule
<<anova-ovos3, results="asis">>=

auxC2 <- lapply(fmodels.ovos, function(x) x$C2)
tab <- do.call("getAnova", c(print = FALSE, auxC2))
tab <- cbind(tab, sapply(auxC2, function(x) coef(x)[1]))
rownames(tab) <- paste("Preditor", rownames(tab))
print(xtable(tab, digits = digits),
      include.colnames = FALSE,
      hline.after = NULL,
      only.contents = TRUE)

@
\specialrule{0em}{0.5em}{0em} %% Apenas para espaçamento
  Quasi-Poisson & np & QDev & AIC & F & diff np & P($>F$) & $\hat{\sigma}$ \\
  \midrule
<<anova-ovos4, results="asis">>=

auxQP <- lapply(fmodels.ovos, function(x) x$QP)
tab <- do.call("getAnova", c(print = FALSE, auxQP))
tab <- cbind(tab, sapply(auxQP, function(x) summary(x)$dispersion))
rownames(tab) <- paste("Preditor", rownames(tab))
print(xtable(tab, digits = digits),
      include.colnames = FALSE,
      hline.after = NULL,
      only.contents = TRUE)

@
 \bottomrule
\end{tabularx}
\vspace{-1mm}

\footnotesize \raggedright np, number of parameters; diff $\ell$,
difference in log-lokelihoods; QDev, quasi-deviance, F, F statistics
based on quasi-deviances; diff np, difference in np.
\end{table}

\autoref{tab:anova-ovos} summarizes the results of fitted models and
likelihood ratio tests comparing the sequence of predictors. All models
indicate the cubic effect of nitrofen dosing. Considering this
predictor, there is an evidence of equidispersed counts, $\phi$
estimates of COM-Poisson close to zero and $\sigma$ of quasi-Poisson, to
one. It is interesting to note that if we omit the effects of a greater
order on the predictor, the modes show evidence of overdispersion
counts. This exemplifies the discussion about causes of overdispersion
made in \autoref{introduction}. We can also note that the quasi-Poisson
approach, although robust to equisdispersion assumption, shows a higher
descriptive levels ($p$-values) than parametric models, that is, the
tests under parametric models are most powerful than quasi-Poisson
models in the equidispersed case.

In \autoref{tab:coef-ovos} we presented the estimates of the regression
parameters considering the cubic dose effect (third predictor). The
interpretations are similar to the discussed in the others cases
studies, but in this the Poisson model is also suitable for indicating
the significance of the effects. In addition, note that the parameters
of the standard COM-Poisson model are comparable to the others models,
this occurs because it is the particular case $\phi = 0$ which implies
$\lambda = \mu$. \autoref{fig:pred-ovos} shows the number of live
offsprings observed in experiment with fitted curves and confidence
bands for all model strategies adopted.

\begin{table}[H]
\centering
\caption{Parameter estimates (Est) and ratio between estimate and
  standard error (SE) for the four model strategies for the nitrofen
  experiment.}
\label{tab:coef-ovos}
\begin{tabularx}{\textwidth}{lCCCCCCCC}
  \toprule
  & \multicolumn{2}{c}{Poisson} &
    \multicolumn{2}{c}{COM-Poisson} &
    \multicolumn{2}{c}{COM-Poisson$_\mu$} &
    \multicolumn{2}{c}{Quasi-Poisson} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9}
<<coef-ovos, results="asis">>=

#-----------------------------------------------------------------------
# Goodness of fit measures and estimate parameters

# GoF measures
measures.ovos <- lapply(models.ovos, function(x)
    c("LogLik" = logLik(x), "AIC" = AIC(x), "BIC" = BIC(x)))

# Get the estimates
co2 <- coef(m2C2)
est <- lapply(models.ovos, FUN = function(x) getCoefs(x))
est.ovos <- do.call(cbind, est)[-1, ]

# Organize in table
pnames <- paste0("\\beta_{", 0:3, "}")
rownames(est.ovos) <- paste0("$", pnames, "$")
print.xtable(xtable(est.ovos, digits = 4),
             hline.after = c(0, nrow(est.ovos)),
             only.contents = TRUE)

@
\end{tabularx}
\end{table}

The fitted values and confidence bands in \autoref{fig:pred-ovos} come
to have a full overlay. This shows that even in case where is not
necessary to estimate the precision parameter $\phi$, but estimating it
does not lead to incorrect analysis.

<<pred-ovos, fig.height=3.5, fig.width=5.5, out.width="0.7\\textwidth", fig.cap="Number of live offsprings observed for each nitrofen concentration level with fitted curves and 95\\% confidence intervals.">>=

#-----------------------------------------------------------------------
# Prediction

# Data for prediction
pred <- with(nitrofen,
             data.frame("dose" = seq(min(dose), max(dose),
                                     length.out = 100)))
qn <- qnorm(0.975) * c(fit = 0, lwr = -1, upr = 1)

# Design matrix for prediction
X <- model.matrix(update(form3, NULL ~ .), pred)

# Considering Poisson
aux <- exp(confint(
    glht(m3PO, linfct = X), calpha = univariate_calpha())$confint)
colnames(aux) <- c("fit", "lwr", "upr")
aux <- data.frame(modelo = "Poisson", aux)
predPO.novos <- cbind(pred, aux)

# Considering COM-Poisson
aux <- predictcm(m3C1, newdata = X)
aux <- data.frame(modelo = "COM-Poisson", aux)
predC1.novos <- cbind(pred, aux)

# Considering COM-Poisson (mean parametrization)
aux <- predictcm(m3C2, newdata = X)
aux <- data.frame(modelo = "COM-Poisson2", aux)
predC2.novos <- cbind(pred, aux)

# Considering Quasi-Poisson
aux <- exp(confint(
    glht(m3QP, linfct = X), calpha = univariate_calpha())$confint)
colnames(aux) <- c("fit", "lwr", "upr")
aux <- data.frame(modelo = "Quasi-Poisson", aux)
predQP.novos <- cbind(pred, aux)

# Representing the confidence intervals
pred.novos <- rbind(predPO.novos, predC1.novos, predC2.novos, predQP.novos)
ord <- order(pred.novos$dose, pred.novos$modelo)
pred.novos <- pred.novos[ord, ]

# Legend
key <- list(columns = 2,
            lines = list(col = 1, lty = rev(1:4)),
            text = list(parse(
                text = c("'Poisson'", "'COM-Poisson'",
                         "'COM-Poisson'[mu]", "'Quasi-Poisson'"))
                )
            )

# Graph
xyplot(novos ~ dose,
       data = nitrofen,
       xlab = "Nitrofen concentration level",
       ylab = "Number of live offspring",
       grid = TRUE,
       alpha = 0.6,
       key = key,
       spread = 0.05,
       panel = panel.beeswarm) +
    as.layer(
        xyplot(fit ~ dose,
               auto.key = TRUE,
               data = pred.novos,
               groups = modelo,
               type = "l",
               col = 1,
               ly = pred.novos$lwr,
               uy = pred.novos$upr,
               cty = "bands",
               fill = "gray80",
               alpha = 0.1,
               panel = panel.superpose,
               panel.groups = panel.cbH,
               prepanel = prepanel.cbH,
               lty = rev(1:4))
    )

@

Finally, in \autoref{tab:corr-ovos} we presented the empirical
correlations between regression and precision parameters. The results
show that even in the particular case ($\phi=0$), the empirical
correlations for the standard models are not zero. For the
reparametrized model, as discussed in the previous sections, the
correlations are practically null.

<<corr-ovos, results="asis">>=

#-----------------------------------------------------------------------
# Correlation between estimates
corr.ovos <- do.call("rbind",
                     lapply(models.ovos[c("C1", "C2")],
                            function(x) cov2cor(vcov(x))[1, -1]))

# Organize on table
rownames(corr.ovos) <- paste0("COM-Poisson", c("", "$_\\mu$"))
colnames(corr.ovos) <- gsub("(beta)", "hat{\\\\\\1}", pnames)

caption <- paste("Empirical correlations between $\\hat{\\phi}$ and",
                 "$\\hat{\\bm{\\beta}}$ for the two parametrizations",
                 "of COM-Poisson model fit to equidispersed data.")
print(xtable(corr.ovos,
             align = c("lCCCC"),
             caption = caption,
             digits = 3,
             label = "tab:corr-ovos"),
      # size = "small",
      sanitize.rownames.function = identity,
      sanitize.colnames.function = function(x) sprintf("$%s$", x),
      tabular.environment = "tabularx",
      width = "\\textwidth")

@

\section{Concluding remarks}
\label{conclusion}

%-----------------------------------------------------------------------
\newpage

\small
\bibliography{references.bib}
\end{document}
